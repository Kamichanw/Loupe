defaults:
  - default
  - _self_

fpn_scales: [0.5, 2, 4] # rescale the last hidden states of backbone. for PE-Core-L14-336, rescale to 12x12, 48x48, 96x96
freeze_backbone: True
freeze_seg: False
# tversky alpha and beta control the weight of false positive and false negative, respectively
# the tversky beta is set to 1 - alpha
tversky_alpha: 0.7
# weight for forged pixels, set between 0 and 1
pixel_forge_weight: 0.9
# epsilon for poly1 focal loss
pixel_poly_epsilon: 1.0
# backbone_path: /gemini/code/loupe/checkpoints/cls/model.safetensors # if can also be a path to a cls checkpoint

# mask2former overrides, you can set attr to '-' to use default value
# visit https://huggingface.co/docs/transformers/main/model_doc/mask2former#transformers.Mask2FormerConfig for available overrides
mask2former_overrides:
  num_queries: 20
  mask_weight: 0 # MUST BE 0 FOR OUR TASK
  class_weight: 2
  dice_weight: 5
  id2label:
    0: "forgery"
  label2id:
    forgery: 0

