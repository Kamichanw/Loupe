defaults:
  - default
  - _self_

fpn_scales: [0.5, 2, 4] # rescale the last hidden states of backbone. for PE-Core-L14-336, rescale to 12x12, 48x48, 96x96
freeze_backbone: True
freeze_seg: False
# tversky alpha and beta control the weight of false positive and false negative, respectively
# the tversky beta is set to 1 - alpha
tversky_alpha: 0.7
# alpha for focal loss on mask prediction, 1 for foreground and 0 for background
seg_pixel_focal_alpha: 0.2
# backbone_path: /gemini/code/loupe/checkpoints/cls/model.safetensors # if can also be a path to a cls checkpoint

mask2former_path: /gemini/code/loupe/pretrained_weights/mask2former
# mask2former overrides, you can set attr to '-' to use default value
# visit https://huggingface.co/docs/transformers/main/model_doc/mask2former#transformers.Mask2FormerConfig for available overrides
mask2former_overrides:
  num_queries: 10
  id2label:
    0: "forgery"
  label2id:
    forgery: 0

